{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Asmat Mehmood\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This dataset was built with the purpose of helping students in shortlisting universities with their profiles. The predicted output gives them a fair idea about their chances for a particular university.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"D:\\My docouments\\Study\\DS NED\\Deep Learning\\Perceptrons\"\n",
    "\n",
    "data = pd.read_csv('./Admission_Predict_Ver1.1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['Serial No.'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,0:-1]\n",
    "y=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying MinMax scaling technique\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(7,activation='relu',input_dim=7)) # Input layer & input dim define the number of features(7), for basic problem mimimum 3 layres needs to add\n",
    "model.add(Dense(7,activation='relu')) # Hidden layeer\n",
    "model.add(Dense(7,activation='relu')) # Hidden layeer\n",
    "model.add(Dense(7,activation='relu')) # Hidden layeer\n",
    "model.add(Dense(1,activation='linear')) #Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 232 (928.00 Byte)\n",
      "Trainable params: 232 (928.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 1s 20ms/step - loss: 0.8651 - val_loss: 0.8604\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7132 - val_loss: 0.7213\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6079 - val_loss: 0.6270\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5409 - val_loss: 0.5716\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5041 - val_loss: 0.5399\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4794 - val_loss: 0.5165\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4600 - val_loss: 0.4972\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4435 - val_loss: 0.4809\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4291 - val_loss: 0.4662\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4160 - val_loss: 0.4526\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4038 - val_loss: 0.4398\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3923 - val_loss: 0.4279\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3814 - val_loss: 0.4163\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3707 - val_loss: 0.4052\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3605 - val_loss: 0.3942\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3504 - val_loss: 0.3836\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3405 - val_loss: 0.3732\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3310 - val_loss: 0.3630\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3215 - val_loss: 0.3530\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3123 - val_loss: 0.3433\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3033 - val_loss: 0.3337\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2945 - val_loss: 0.3244\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2859 - val_loss: 0.3153\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2775 - val_loss: 0.3063\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2693 - val_loss: 0.2975\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2613 - val_loss: 0.2890\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2533 - val_loss: 0.2806\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2456 - val_loss: 0.2723\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2379 - val_loss: 0.2638\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2298 - val_loss: 0.2546\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2207 - val_loss: 0.2439\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2101 - val_loss: 0.2310\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1970 - val_loss: 0.2148\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1805 - val_loss: 0.1945\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.1695\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1364 - val_loss: 0.1407\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1093 - val_loss: 0.1087\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0804 - val_loss: 0.0747\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0513 - val_loss: 0.0427\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0187\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0078\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_scaled,y_train,epochs=500,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8144979047255636"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error, mean_squared_error\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.04177499228715896\n",
      "Mean Squared Error (MSE): 0.00358223096184464\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f27448af90>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mae'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Plot training & validation MAE\u001b[39;00m\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain MAE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mae\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation MAE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel MAE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mae'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting training & validation metrics\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Plot training & validation MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
